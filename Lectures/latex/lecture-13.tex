\section{Lecture 13: Detailed MIPS Pipeline Operation and Pipeline Registers}

\emph{By Dr. Isuru Nawinne}

\subsection{Introduction}

This lecture provides comprehensive, cycle-by-cycle analysis of MIPS five-stage pipeline operation, examining how instructions flow through pipeline stages with detailed attention to the pipeline registers that store intermediate results between stages. We explore the critical role of these registers in enabling independent stage operation, trace complete execution sequences for load and store instructions, analyze timing constraints and delay contributions, and work through practical exercises calculating clock frequencies and optimizing pipeline performance. This detailed examination reveals the hardware mechanisms that transform the conceptual pipeline model into functioning silicon.

\subsection{Lecture Introduction and Recap}

\subsubsection{Previous Topics Review}

\textbf{Pipelining Concept:}

\begin{itemize}
\item Instruction-level parallelism exploitation
\item Five-stage MIPS pipeline: IF, ID, EX, MEM, WB
\item Staggered instruction execution
\item All hardware utilized simultaneously

\textbf{Performance Metric:}

\begin{itemize}
\item Throughput improved (not latency)
\item Instructions/unit time increased
\item Individual instruction latency same or worse
\item Overall system performance dramatically better

\textbf{Hazards Covered:}

\begin{enumerate}
\item \textbf{Structural:} Hardware resource conflicts
\item \textbf{Data:} Register/memory dependencies
\item \textbf{Control:} Branch/jump decision delays

\textbf{Solutions Discussed:}

\begin{itemize}
\item Structural: Separate I-cache and D-cache
\item Data: Forwarding, code reordering
\item Control: Early branch resolution, prediction

\subsubsection{Today's Focus}

\textbf{Detailed Pipeline Analysis:}

\begin{itemize}
\item Cycle-by-cycle operation walkthrough
\item Pipeline register requirements
\item Timing and delay analysis
\item Load/Store instruction examples
\item Common implementation errors
\item Practical exercises

\subsection{Five-Stage MIPS Pipeline Review}

\subsubsection{Stage 1: Instruction Fetch (IF)}

\textbf{Operations:}

\begin{itemize}
\item PC value determines instruction address
\item Access instruction memory
\item Fetch 32-bit instruction word
\item Calculate PC + 4 for next sequential instruction

\textbf{Hardware Elements:}

\begin{itemize}
\item Program Counter register
\item Instruction Memory
\item PC + 4 Adder

\textbf{Key Point:}

\begin{itemize}
\item Both operations (memory read, PC+4 calculation) occur in parallel

\subsubsection{Stage 2: Instruction Decode / Register Read (ID)}

\textbf{Operations:}

\begin{itemize}
\item Decode opcode (6 bits)
\item Determine instruction type
\item Identify register fields
\item Read register file (RS, RT)
\item Sign-extend immediate value (16$\rightarrow$32 bits)
\item Generate control signals

\textbf{Hardware Elements:}

\begin{itemize}
\item Instruction decoder (combinational logic)
\item Register file (read ports)
\item Sign extension unit
\item Control unit

\textbf{Workload Balancing:}

\begin{itemize}
\item Decode + register read fit in one cycle
\item Even distribution of work
\item Register read dominates timing

\textbf{Control Signal Generation:}

\begin{itemize}
\item 9-10 control signal bits generated
\item Based on opcode
\item Used by subsequent stages
\item Must be preserved through pipeline

\subsubsection{Stage 3: Execution (EX)}

\textbf{Operations:}

\begin{itemize}
\item ALU performs computation OR address calculation
\item Multiplexer selects second operand (register vs immediate)
\item Branch: Compare registers, compute target address

\textbf{Hardware Elements:}

\begin{itemize}
\item ALU (Arithmetic Logic Unit)
\item Input multiplexer (register/immediate selection)
\item Branch target adder (parallel to ALU)
\item Shift left 2 unit (for branch offset)

\textbf{Key Characteristics:}

\begin{itemize}
\item ALU operation dominates timing
\item Branch hardware operates in parallel
\item Multiple functions depending on instruction type

\subsubsection{Stage 4: Memory Access (MEM)}

\textbf{Operations:}

\begin{itemize}
\item Load: Read from data memory
\item Store: Write to data memory
\item Other instructions: Skip (no memory access)
\item Branch: PC update decision

\textbf{Hardware Elements:}

\begin{itemize}
\item Data Memory
\item PC source multiplexer (for branches)

\textbf{Timing Consideration:}

\begin{itemize}
\item Memory access slowest operation
\item Dominates stage timing
\item Critical path component

\subsubsection{Stage 5: Write Back (WB)}

\textbf{Operations:}

\begin{itemize}
\item Select data source (ALU result OR memory data)
\item Write to destination register
\item Load: Memory data $\rightarrow$ register
\item Arithmetic: ALU result $\rightarrow$ register

\textbf{Hardware Elements:}

\begin{itemize}
\item MemtoReg multiplexer
\item Register file (write port)

\textbf{Minimal Hardware:}

\begin{itemize}
\item Mostly multiplexer visible
\item Register file shared with ID stage
\item Shortest stage conceptually

\subsection{Pipeline Registers: Necessity and Function}

\subsubsection{Problem Without Pipeline Registers}

\textbf{Scenario:}

\begin{itemize}
\item Multiple instructions in different stages
\item All sharing same hardware components
\item Data from different instructions 混淆

\textbf{Example Issues:}

\begin{enumerate}
\item Register file: ID stage reads while WB stage writes
\item Control signals: Generated in ID, needed in later stages
\item Data values: Computed in EX, needed in MEM
\item Overwriting: New instruction data overwrites previous instruction data

\textbf{Result Without Pipeline Registers:}

\begin{itemize}
\item Data hazards everywhere
\item Control hazards from signal conflicts
\item Structural hazards from resource contention
\item Pipeline cannot function correctly

\subsubsection{Pipeline Register Purpose}

\textbf{Key Function:}

\begin{itemize}
\item Store information from previous stage
\item Make data available to next stage
\item Synchronize operations across clock cycles
\item Prevent interference between instructions

\textbf{Placement:}

\begin{itemize}
\item One between each pair of consecutive stages
\item \textbf{IF/ID:} Between instruction fetch and decode
\item \textbf{ID/EX:} Between decode and execution
\item \textbf{EX/MEM:} Between execution and memory
\item \textbf{MEM/WB:} Between memory and write back

\textbf{Exception:}

\begin{itemize}
\item No register between WB and IF
\item PC register serves this purpose
\item Register file contains storage
\item No additional register needed

\subsubsection{Pipeline Register Contents}

\textbf{IF/ID Pipeline Register:}

\begin{itemize}
\item 32-bit instruction word
\item 32-bit PC+4 value
\item \textbf{Total:} 64 bits

\textbf{ID/EX Pipeline Register:}

\begin{itemize}
\item Two 32-bit register values (from register file)
\item 32-bit sign-extended immediate
\item 32-bit PC+4 value (for branches)
\item 5-bit write register address
\item 9-10 control signal bits
\item \textbf{Total:} ~140+ bits (largest pipeline register)

\textbf{EX/MEM Pipeline Register:}

\begin{itemize}
\item 32-bit ALU result
\item 32-bit register value (for stores)
\item 32-bit branch target address
\item 1-bit ALU zero flag
\item 5-bit write register address
\item Control signals for MEM/WB stages
\item \textbf{Total:} ~105+ bits

\textbf{MEM/WB Pipeline Register:}

\begin{itemize}
\item 32-bit memory read data
\item 32-bit ALU result
\item 5-bit write register address
\item Control signals for WB stage
\item \textbf{Total:} ~75+ bits

\subsubsection{Timing: Writing and Reading Pipeline Registers}

\textbf{At Rising Clock Edge:}

\begin{enumerate}
\item Pipeline register write begins
\item Small hold time delay (~10-30 ps)
\item Data captured and stored
\item Writing delay consumed

\textbf{After Writing:} 5. Reading delay begins 6. Data propagates to output (~10-30 ps) 7. Outputs stabilize at new values 8. Next stage begins operations

\textbf{Combined Overhead:}

\begin{itemize}
\item Write delay + read delay = ~20-60 ps
\item Occurs at start of every stage
\item Reduces time available for actual computation
\item Pipelining overhead cost

\textbf{Critical Observation:}

\begin{itemize}
\item These delays don't exist in single-cycle
\item Pipelining adds latency overhead
\item But throughput gain outweighs latency cost

\subsection{Load Word Instruction: Detailed Cycle-by-Cycle Analysis}

\subsubsection{Load Word Instruction Format}

\textbf{Encoding:}

LW $rt, offset($rs)

Opcode: 100011 (bits 26-31)
RS:     Base register (bits 21-25)
RT:     Destination register (bits 16-20)
Offset: 16-bit immediate (bits 0-15)

\textbf{Operation:} $rt = Memory[$rs + offset]

\textbf{Example:} LW $8, 32($9)

\begin{itemize}
\item Base address in $9
\item Add offset 32
\item Load from memory into $8

\subsubsection{Clock Cycle 1: Instruction Fetch (IF)}

\textbf{Start of Cycle:}

\begin{itemize}
\item New PC value available (from previous cycle)
\item PC write delay: ~10-30 ps
\item PC read delay: ~10-30 ps

\textbf{Operations:}

\begin{enumerate}
\item Update PC register (rising edge)
\item Read PC value (small delay)
\item Access instruction memory with PC address
\item Instruction memory read delay: ~200 ps (dominant)
\item Compute PC + 4 in parallel: ~70 ps

\textbf{End of Cycle:}

\begin{itemize}
\item 32-bit LW instruction available
\item PC + 4 value available
\item Both ready to write to IF/ID register

\textbf{Hardware Shading Convention:}

\begin{itemize}
\item Right side shaded: Device READ
\item Left side shaded: Device WRITTEN
\item Example: Instruction Memory right-side shaded (read)
\item IF/ID register left-side shaded (written to)

\textbf{Total Stage Time:} ~200+ ps (instruction memory dominant)

\subsubsection{Clock Cycle 2: Instruction Decode / Register Read (ID)}

\textbf{Start of Cycle (Rising Edge):}

\begin{enumerate}
\item IF/ID register write: ~30 ps
\item IF/ID register read: ~30 ps
\item Combined delay: ~60 ps

\textbf{After Pipeline Register:} 4. Instruction word available 5. Extract fields:

\begin{itemize}
\item Opcode: bits 26-31 $\rightarrow$ Control Unit
\item RS (bits 21-25) $\rightarrow$ Register file address 1
\item RT (bits 16-20) $\rightarrow$ Register file address 2 AND write address
\item Offset (bits 0-15) $\rightarrow$ Sign extender

\textbf{Parallel Operations:}

\begin{itemize}
\item Control Unit: Decode opcode $\rightarrow$ Generate control signals (~50 ps)
\item Register File: Read RS ($9) and RT ($8 address, value not needed)
\item Read delay: ~90 ps (dominant)
\item Sign Extender: Extend 32 to 32 bits (~10 ps, negligible)

\textbf{End of Cycle:}

\begin{itemize}
\item Base address value (from $9) available
\item RT address read (discarded for LW)
\item Sign-extended offset (32) available
\item PC + 4 value forwarded
\item Control signals generated
\item All ready for ID/EX register

\textbf{Why Read Both Registers:}

\begin{itemize}
\item Hardware simplicity: Always read both
\item Multiplexer decides usage later
\item Store would need RT value
\item Simpler than conditional reading

\textbf{Total Stage Time:} ~60 + 90 = ~150 ps (register read dominant)

\subsubsection{Clock Cycle 3: Execution (EX)}

\textbf{Start of Cycle:}

\begin{enumerate}
\item ID/EX register write: ~30 ps
\item ID/EX register read: ~30 ps

\textbf{ALU Input Preparation:} 3. Input A: Base address (from $9) directly from pipeline register 4. Input B: Multiplexer selects immediate OR register

\begin{itemize}
\item Control signal ALUSrc = 1 (select immediate)
\item Multiplexer delay: ~20 ps
\item Sign-extended offset (32) selected

\textbf{ALU Operation:} 5. Add base address + offset 6. ALU delay: ~90 ps (dominant) 7. Result: Memory address = $9 + 32

\textbf{Parallel Operations (for branches, not used here):}

\begin{itemize}
\item Shift left 2: Offset $\times$ 4 (~10 ps)
\item Branch target adder: PC+4 + (offset$\times$4) (~70 ps)
\item Zero flag generation

\textbf{End of Cycle:}

\begin{itemize}
\item Memory address available at ALU output
\item Branch target available (unused)
\item Zero flag available (unused)
\item RT value forwarded (unused for LW)
\item Control signals forwarded
\item Write register address (RT) forwarded
\item All ready for EX/MEM register

\textbf{Total Stage Time:} ~30 + 30 + 20 + 90 = ~170 ps (ALU dominant)

\subsubsection{Clock Cycle 4: Memory Access (MEM)}

\textbf{Start of Cycle:}

\begin{enumerate}
\item EX/MEM register write: ~30 ps
\item EX/MEM register read: ~30 ps

\textbf{Memory Access:} 3. ALU result (address) $\rightarrow$ Data memory address input 4. MemRead control signal = 1 (enable read) 5. MemWrite control signal = 0 (disable write) 6. Data memory read delay: ~250 ps (\textbf{DOMINANT} - slowest operation!)

\textbf{Parallel Operations (unused for LW):}

\begin{itemize}
\item Zero flag + Branch $\rightarrow$ PCSrc decision
\item Branch target $\rightarrow$ PC multiplexer

\textbf{End of Cycle:}

\begin{itemize}
\item Loaded data available from memory
\item ALU result (address) forwarded for R-type instructions
\item Write register address (RT) forwarded
\item Control signals forwarded
\item All ready for MEM/WB register

\textbf{Critical Path:}

\begin{itemize}
\item Load Word determines minimum clock period
\item Memory access slowest component
\item All other instructions wait for this

\textbf{Total Stage Time:} ~30 + 30 + 250 = ~310 ps (memory READ dominant!)

\subsubsection{Clock Cycle 5: Write Back (WB)}

\textbf{Start of Cycle:}

\begin{enumerate}
\item MEM/WB register write: ~30 ps
\item MEM/WB register read: ~30 ps

\textbf{Data Selection:} 3. MemtoReg multiplexer:

\begin{itemize}
\item Control signal MemtoReg = 1 (select memory data)
\item Input 0: ALU result (not used for LW)
\item Input 1: Memory read data (\textbf{SELECTED})
\item Multiplexer delay: ~20 ps

\textbf{Register Write Preparation:} 4. Write data: Memory data from multiplexer 5. Write address: RT ($8) from pipeline register 6. RegWrite control signal = 1 (enable write)

\textbf{CRITICAL ERROR IN TEXTBOOK DIAGRAM:}

\begin{itemize}
\item Many diagrams show write address from IF/ID register
\item \textbf{WRONG!} IF/ID has current instruction (4 cycles later!)
\item \textbf{Correct:} Write address propagated through ALL pipeline registers
\item Must use write address from MEM/WB register

\textbf{At Rising Edge (End of Cycle / Start of Next):} 7. Register $8 written with loaded data 8. Write occurs in first half of cycle 9. Subsequent ID stage can read in second half (same cycle!)

\textbf{Register File Timing Trick:}

\begin{itemize}
\item Write: First half of clock cycle
\item Read: Second half of clock cycle
\item Enables read-after-write in adjacent cycles
\item Critical for data forwarding

\textbf{Total Stage Time:} ~30 + 30 + 20 = ~80 ps (shortest stage!)

\subsubsection{Load Word Complete Pipeline Summary}

| Cycle | Stage | Operations                    | Dominant Delay | Time                  |
| ----- | ----- | ----------------------------- | -------------- | --------------------- |
| 1     | IF    | Fetch instruction, PC+4       | Inst Memory    | 200ps                 |
| 2     | ID    | Decode, read regs, control    | Reg Read       | 150ps                 |
| 3     | EX    | ALU: base + offset            | ALU            | 170ps                 |
| 4     | MEM   | Read data memory              | Memory Read    | \textbf{310ps $\leftarrow$ CRITICAL!} |
| 5     | WB    | Select memory, write register | Multiplexer    | 80ps                  |

\textbf{Minimum Clock Period:} 310 ps (limited by MEM stage)
\textbf{Maximum Clock Frequency:} 1 / 310ps ≈ 3.2 GHz

\textbf{Pipeline Overhead:}

\begin{itemize}
\item Pipeline register delays: ~(30+30) $\times$ 5 stages = 300ps
\item Actual useful work: ~(200+90+90+250) = 630ps
\item Total latency: ~930ps
\item Overhead: ~32% of execution time

\textbf{Comparison to Single-Cycle:}

\begin{itemize}
\item Single-cycle latency: ~800 ps (no pipeline register overhead)
\item Pipelined latency: ~930 ps (with overhead)
\item But pipelined throughput: 5$\times$ better (ideally)

\subsection{Store Word Instruction: Key Differences}

\subsubsection{Store Word Instruction Format}

\textbf{Encoding:}

SW $rt, offset($rs)

Opcode: 101011 (bits 26-31)
RS:     Base register (bits 21-25)
RT:     Source data register (bits 16-20)
Offset: 16-bit immediate (bits 0-15)

\textbf{Operation:} Memory[$rs + offset] = $rt

\textbf{Example:} SW $8, 32($9)

\begin{itemize}
\item Base address in $9
\item Add offset 32
\item Store $8 value to memory

\textbf{Key Difference from Load:}

\begin{itemize}
\item RT is SOURCE (not destination)
\item RT value needed for memory write

\subsubsection{Stages IF, ID, EX: Same as Load Word}

\textbf{Instruction Fetch:} Identical to LW

\textbf{Instruction Decode:} Identical to LW

\begin{itemize}
\item Read both RS and RT
\item RT value NOW IMPORTANT (not discarded)
\item Sign-extend offset

\textbf{Execution:} Identical to LW

\begin{itemize}
\item Compute memory address: base + offset
\item ALU operation same

\subsubsection{Memory Access Stage: KEY DIFFERENCE}

\textbf{Start of Cycle:}

\begin{itemize}
\item EX/MEM register contains:
\item Memory address (from ALU)
\item RT data value (from register file, preserved through pipeline)

\textbf{Memory Access:}

\begin{itemize}
\item Address $\rightarrow$ Data memory address input
\item RT value $\rightarrow$ Data memory write data input
\item MemWrite = 1 (\textbf{ENABLE} write)
\item MemRead = 0 (\textbf{DISABLE} read)

\textbf{Operation:}

\begin{itemize}
\item Write RT value to computed address
\item Memory write delay: ~250 ps

\textbf{End of Cycle:}

\begin{itemize}
\item Data written to memory
\item Memory read output INVALID (MemRead=0)
\item Not used by subsequent stage

\textbf{Control Signal Critical:}

| Control Signal      | Load | Store             |
| ------------------- | ---- | ----------------- |
| MemRead             | 1    | 0                 |
| MemWrite            | 0    | 1                 |
| RegWrite (WB stage) | 1    | \textbf{0 $\leftarrow$ CRITICAL!} |

\subsubsection{Write Back Stage: NO OPERATION}

\textbf{Store Word WB Stage:}

\begin{itemize}
\item NO register write needed
\item Store wrote to MEMORY (not register)
\item RegWrite = 0 (\textbf{DISABLE})

\textbf{Why RegWrite MUST Be 0:}

\begin{itemize}
\item Pipeline registers still contain data
\item MemtoReg multiplexer produces output
\item If RegWrite = 1: \textbf{DISASTER!}
\item Random data written to random register
\item Data corruption
\item Program failure

\textbf{Hardware Still Operates:}

\begin{itemize}
\item Multiplexer produces output (garbage)
\item Write address present (RT from pipeline)
\item Write data present (memory output = invalid, or ALU result)
\item But RegWrite = 0 prevents write

\textbf{Lesson: Control Signals Essential}

\begin{itemize}
\item Must prevent unwanted operations
\item Hardware runs in parallel
\item Only control signals prevent corruption

\textbf{Store Word Pipeline Summary:}

| Cycle | Stage | Operations           | Notes                         |
| ----- | ----- | -------------------- | ----------------------------- |
| 1     | IF    | Fetch SW instruction | Same as LW                    |
| 2     | ID    | Decode, read RS, RT  | RT value USED (not discarded) |
| 3     | EX    | Compute address      | Same as LW                    |
| 4     | MEM   | Write RT to memory   | \textbf{WRITE} instead of read     |
| 5     | WB    | Nothing (bubble)     | RegWrite=0, stage idle        |

\subsection{Common Pipeline Diagram Errors}

\subsubsection{Error 1: Write Register Address Source}

\textbf{Incorrect Diagram Shows:}

\begin{itemize}
\item Write register address from IF/ID pipeline register
\item Connected directly to register file write port

\textbf{Why This Is Wrong:}

\begin{itemize}
\item IF/ID contains CURRENT instruction (just fetched)
\item Write back for instruction 4 cycles ago
\item Wrong register would be written!

\textbf{Example:}

Cycle 1: LW $8, 0($10) fetched  (IF)
Cycle 2: LW $9, 4($10) fetched  (IF), LW $8 in ID
Cycle 3: LW $10, 8($10) fetched (IF), LW $8 in EX
Cycle 4: ADD $11, $12, $13 fetched (IF), LW $8 in MEM
Cycle 5: SUB $14, $15, $16 fetched (IF), LW $8 in WB

At Cycle 5:
\begin{itemize}
\item IF/ID contains SUB (writes $14)
\item WB should write $8 (from LW)
\item If using IF/ID: Would write to $14 instead of $8!
\item WRONG REGISTER!

\textbf{Correct Implementation:}

\begin{itemize}
\item Propagate write address through ALL pipeline registers
\item ID/EX stores it
\item EX/MEM stores it
\item MEM/WB stores it
\item WB uses address from MEM/WB register

\textbf{Additional Lines Required:}

\begin{itemize}
\item 5-bit write address bus through each pipeline register
\item Increases pipeline register size
\item Essential for correctness

\subsubsection{Error 2: Incorrect Memory Access Indication}

\textbf{Diagram Error from Textbook:}

\begin{itemize}
\item ADD instruction shown accessing data memory (wrong!)
\item LW instruction shown NOT accessing data memory (wrong!)

\textbf{Correct Resource Usage:}

| Instruction | IF  | ID  | EX  | MEM         | WB          |
| ----------- | --- | --- | --- | ----------- | ----------- |
| LW          | ✓   | ✓   | ✓   | ✓ Read      | ✓ Write Reg |
| SW          | ✓   | ✓   | ✓   | ✓ Write     | No action   |
| ADD         | ✓   | ✓   | ✓   | ✗ No access | ✓ Write Reg |
| BEQ         | ✓   | ✓   | ✓   | ✗ PC update | ✗ No write  |

\textbf{Shading Convention:}

\begin{itemize}
\item Shaded box: Resource USED
\item Unshaded box: Resource NOT USED (idle)

\textbf{ADD Instruction Correct:}

\begin{itemize}
\item MEM stage: No memory access, stage mostly idle
\item Just forwards ALU result

\textbf{LW Instruction Correct:}

\begin{itemize}
\item MEM stage: Read from data memory
\item Memory data forwarded to WB

\subsubsection{Error 3: Store Word Memory Read}

\textbf{Another Common Error:}

\begin{itemize}
\item Store instruction shown with MemRead = 1
\item Memory output shown as valid

\textbf{Why Wrong:}

\begin{itemize}
\item Store WRITES to memory (MemWrite = 1)
\item Should NOT read (MemRead = 0)
\item Memory read output undefined/invalid

\textbf{Correct:}

\begin{itemize}
\item MemWrite = 1, MemRead = 0
\item Memory input: Address and write data
\item Memory output: Ignored (invalid)

\subsection{Multi-Clock-Cycle Pipeline Diagrams}

\subsubsection{Single-Clock vs Multi-Clock Diagrams}

\textbf{Single-Clock-Cycle Diagram:}

\begin{itemize}
\item Shows ONE stage at ONE clock cycle
\item Detailed resource usage
\item Specific delays visible
\item Good for understanding individual stage

\textbf{Multi-Clock-Cycle Diagram:}

\begin{itemize}
\item Shows MULTIPLE instructions at MULTIPLE cycles
\item Cross-sectional view of pipeline
\item Parallel execution visible
\item Good for understanding overall flow

\subsubsection{Traditional Multi-Cycle Diagram}

\textbf{Format:}

          Cycle: 1    2    3    4    5    6    7    8    9
Instr 1:         IF   ID   EX   MEM  WB
Instr 2:              IF   ID   EX   MEM  WB
Instr 3:                   IF   ID   EX   MEM  WB
Instr 4:                        IF   ID   EX   MEM  WB
Instr 5:                             IF   ID   EX   MEM  WB

\textbf{Shows:}

\begin{itemize}
\item Staggered execution
\item Steady state (cycle 5: all stages busy)
\item Pipeline fill time (cycles 1-4)
\item Pipeline drain time (cycles 7-9)

\textbf{Does NOT Show:}

\begin{itemize}
\item Resource usage details
\item Hardware components used
\item Delays and timing

\subsubsection{Enhanced Multi-Cycle Diagram with Resources}

\textbf{Format:}

Cycle 1:  Instr 1: [IM][RF][  ][  ][  ]
Cycle 2:  Instr 1: [  ][IM][RF][  ][  ]   Instr 2: [IM][RF][  ][  ][  ]
Cycle 3:  Instr 1: [  ][  ][IM][RF][  ]   Instr 2: [  ][IM][RF][  ][  ]   Instr 3: [IM][RF][  ][  ][  ]
...

Legend:
IM: Instruction Memory
RF: Register File
ALU: ALU operation
DM: Data Memory
WB: Write Back

\textbf{Shows:}

\begin{itemize}
\item Which resources used when
\item Parallel resource usage
\item Resource conflicts (if any)
\item Detailed pipeline state

\textbf{Benefits:}

\begin{itemize}
\item Visualize structural hazards
\item Understand resource contention
\item See idle hardware
\item Verify correctness

\textbf{Textbook Error Example:}

\begin{itemize}
\item ADD instruction marked with DM (wrong!)
\item LW instruction NOT marked with DM (wrong!)
\item Always verify diagrams carefully

\subsection{Timing and Clock Frequency Analysis}

\subsubsection{Component Delays (Typical Values)}

| Component               | Delay (picoseconds) |
| ----------------------- | ------------------- |
| Instruction Memory      | 200                 |
| Register File Read      | 90                  |
| Register File Write     | 90                  |
| ALU Operation           | 90                  |
| Data Memory Read        | 250                 |
| Data Memory Write       | 250                 |
| Sign Extension          | 10 (negligible)     |
| Multiplexer             | 20                  |
| Adder (PC+4, branch)    | 70                  |
| Shift Left 2            | 10 (wire routing)   |
| Pipeline Register Write | 30                  |
| Pipeline Register Read  | 30                  |

\textbf{Key Observations:}

\begin{itemize}
\item Memory operations slowest (200-250 ps)
\item ALU and register file moderate (90 ps)
\item Small combinational logic fast (10-20 ps)
\item Pipeline register overhead (60 ps per stage)

\subsubsection{Stage Timing Calculation}

\textbf{Stage 1: Instruction Fetch (IF)}

Pipeline Register Write:   N/A (PC register)
Pipeline Register Read:    N/A
Instruction Memory:        200 ps
PC + 4 Adder:              70 ps (parallel)

Total: 200 ps (memory dominant)

\textbf{Stage 2: Instruction Decode (ID)}

IF/ID Write + Read:        60 ps
Register File Read:        90 ps (dominant)
Control Unit Decode:       50 ps (parallel)
Sign Extension:            10 ps (parallel)

Total: 60 + 90 = 150 ps

\textbf{Stage 3: Execution (EX)}

ID/EX Write + Read:        60 ps
Multiplexer:               20 ps
ALU Operation:             90 ps
Branch Adder:              70 ps (parallel)
Shift Left 2:              10 ps (parallel)

Total: 60 + 20 + 90 = 170 ps

\textbf{Stage 4: Memory Access (MEM)}

EX/MEM Write + Read:       60 ps
Data Memory Access:        250 ps (DOMINANT)

Total: 60 + 250 = 310 ps $\leftarrow$ CRITICAL PATH!

\textbf{Stage 5: Write Back (WB)}

MEM/WB Write + Read:       60 ps
MemtoReg Multiplexer:      20 ps
Register File Write:       30 ps (first half of cycle)

Total: 60 + 20 + 30 = 110 ps

\subsubsection{Clock Frequency Determination}

\textbf{Minimum Clock Period:}

\begin{itemize}
\item Determined by SLOWEST stage
\item MEM stage: 310 ps
\item All stages must use this period

\textbf{Maximum Clock Frequency:}

f_max = 1 / T_min
      = 1 / 310 ps
      = 1 / (310 $\times$ 10^-12 s)
      = 3.226 GHz
      ≈ 3.2 GHz

\textbf{Efficiency Analysis:}

| Stage | Time | Utilization | Wasted Time |
| ----- | ---- | ----------- | ----------- |
| IF    | 200  | 65%         | 110 ps      |
| ID    | 150  | 48%         | 160 ps      |
| EX    | 170  | 55%         | 140 ps      |
| MEM   | 310  | 100%        | 0 ps        |
| WB    | 110  | 35%         | 200 ps      |

\textbf{Average utilization:} ~60%
\textbf{Wasted time:} ~40% average

\subsubsection{Performance Improvement Strategies}

\textbf{Strategy 1: Pipeline Balancing}

\begin{itemize}
\item Reduce MEM stage delay (dominant)
\item Options:
\item Faster memory technology
\item Separate instruction/data caches
\item Smaller, faster cache
\item Multi-ported memory

\textbf{Strategy 2: Increase ALU Time}

\begin{itemize}
\item Question: If ALU shortened by 25%, does it help?
\item Answer: Depends on critical path
\item If MEM is critical (usual case): NO improvement
\item If EX is critical (rare): YES, improves throughput

\textbf{Strategy 3: Additional Pipeline Stages}

\begin{itemize}
\item Subdivide long stages (especially MEM)
\item Memory access in 2-3 sub-stages
\item Shorter clock period possible
\item More stages = more overhead
\item Diminishing returns beyond certain point

\textbf{Strategy 4: Cache Memory}

\begin{itemize}
\item Fast cache between CPU and main memory
\item Cache hit: Fast access (~10-20 ps)
\item Cache miss: Slow access (~250 ps)
\item High hit rate $\rightarrow$ effective fast memory
\item (Covered in next lectures)

\textbf{Real-World Example:}

\begin{itemize}
\item Intel Atom processors: ~30 pipeline stages
\item Achieved by extreme subdivision
\item Very short clock period
\item High frequency possible
\item But diminishing returns and hazard complexity

\subsection{Practical Exercises and Solutions}

\subsubsection{Exercise: Maximum Clock Frequency Calculation}

\textbf{Given Component Delays:}

Instruction Memory:      200 ps
Register File (read):    90 ps
Register File (write):   90 ps
ALU:                     90 ps
Data Memory (read):      250 ps
Data Memory (write):     250 ps
Sign Extend:             ~0 ps
Multiplexer:             20 ps
Adder:                   70 ps
Shift Left 2:            10 ps
Pipeline Register:       30 ps (write), 30 ps (read)

\textbf{Step 1: Calculate each stage timing}

\begin{itemize}
\item IF: 200 + 60 (pipeline reg) = 260 ps
\item ID: 60 + 90 = 150 ps
\item EX: 60 + 20 + 90 = 170 ps
\item MEM: 60 + 250 = 310 ps $\leftarrow$ CRITICAL
\item WB: 60 + 30 = 90 ps

\textbf{Step 2: Identify critical path}

\begin{itemize}
\item Longest stage: MEM at 310 ps

\textbf{Step 3: Calculate maximum frequency}

f_max = 1 / 310 ps
      = 3.226 GHz

\subsubsection{Exercise: Improving Clock Frequency}

\textbf{Question:} Suggest mechanisms to increase clock frequency. Discuss negative impacts.

\textbf{Suggestion 1: Faster Memory Technology}

\begin{itemize}
\item Use SRAM instead of DRAM
\item Reduce memory access time to ~100 ps
\item \textbf{Pros:}
\item Significantly reduces critical path
\item New critical path: IF at 260 ps
\item Frequency increase: 310$\rightarrow$260 (1.2$\times$ improvement)
\item \textbf{Cons:}
\item SRAM very expensive
\item Much larger area
\item Higher power consumption
\item Limited capacity

\textbf{Suggestion 2: Cache Memory (BEST)}

\begin{itemize}
\item Add small, fast cache
\item Cache access: ~50-100 ps
\item Most accesses hit cache
\item \textbf{Pros:}
\item Cost-effective
\item Good performance
\item Scalable
\item Industry standard
\item \textbf{Cons:}
\item Cache misses still slow
\item Complex cache management
\item Additional hardware

\textbf{Suggestion 3: Split Memory Stage}

\begin{itemize}
\item Divide MEM into MEM1 and MEM2
\item Each sub-stage: 185 ps
\item Total stages: 6
\item \textbf{Pros:}
\item More balanced pipeline
\item Higher frequency possible
\item \textbf{Cons:}
\item More pipeline registers (overhead)
\item Increased latency
\item More complex control

\textbf{Suggestion 4: Eliminate Pipeline Register Overhead}

\begin{itemize}
\item Use transparent latches
\item Reduce write+read delay
\item \textbf{Pros:}
\item Removes 60 ps overhead per stage
\item Significant improvement
\item \textbf{Cons:}
\item Timing more complex
\item Clock skew issues
\item Less reliable

\subsubsection{Exercise: ALU Optimization Impact}

\textbf{Question:} ALU time shortened by 25%. Does it affect speedup?

\textbf{Analysis:}

\begin{itemize}
\item Current ALU delay: 90 ps
\item Reduced ALU delay: 90 $\times$ 0.75 = 67.5 ps
\item Savings: 22.5 ps

\textbf{Scenario 1: MEM is Critical Path (Typical)}

\begin{itemize}
\item Current EX stage: 60 + 20 + 90 = 170 ps
\item Optimized EX stage: 60 + 20 + 67.5 = 147.5 ps
\item Current critical path: MEM at 310 ps
\item New critical path: Still MEM at 310 ps
\item Clock period: Still 310 ps
\item Speedup: \textbf{NONE}

\textbf{Conclusion:} No improvement when not on critical path

\textbf{Scenario 2: EX is Critical Path (Hypothetical)}

\begin{itemize}
\item Assume faster memory: MEM = 200 ps
\item Current EX stage: 170 ps (critical)
\item Optimized EX stage: 147.5 ps
\item New critical path: EX at 147.5 ps
\item Clock period: 170 $\rightarrow$ 147.5 ps
\item Improvement: 1.15$\times$ faster

\textbf{Conclusion:} Significant improvement when on critical path

\textbf{General Principle:}

\begin{itemize}
\item Only optimizing critical path improves throughput
\item Non-critical optimizations: No throughput benefit
\item May reduce latency slightly (instruction-by-instruction)

\subsubsection{Exercise: Pipeline Speedup Calculation}

\textbf{Given:}

\begin{itemize}
\item 10^7 instructions (10 million)
\item Non-pipelined: 100 ps per instruction
\item Perfect 20-stage pipeline

\textbf{Part A: Non-pipelined execution time}

Time = Instructions $\times$ Time per instruction
     = 10^7 $\times$ 100 ps
     = 10^9 ps
     = 1 ms (0.001 seconds)

\textbf{Part B: Speedup from 20-stage perfect pipeline}

Ideal Speedup = Number of stages = 20$\times$

\textbf{Part C: Time with perfect pipeline}

Time = (10^7 $\times$ 100 ps) / 20
     = 10^9 / 20 ps
     = 5 $\times$ 10^7 ps
     = 0.05 ms

\textbf{Part D: Real pipeline overhead impact}

\begin{itemize}
\item Overheads affect both latency AND throughput
\item Pipeline register delays: Add to latency
\item Unbalanced stages: Reduce throughput
\item Hazards and stalls: Reduce throughput further

\textbf{Answer: BOTH latency and throughput affected}

\textbf{Latency Impact:}

\begin{itemize}
\item Pipeline register overhead adds to per-instruction time
\item 100 ps $\rightarrow$ ~130 ps per instruction (with overhead)

\textbf{Throughput Impact:}

\begin{itemize}
\item Unbalanced stages reduce effective speedup
\item Perfect 20$\times$ becomes ~15-17$\times$ in reality
\item Critical path limits clock speed

\subsection{Summary and Key Takeaways}

\subsubsection{Pipeline Operation Fundamentals}

\textbf{Pipeline Registers Essential:}

\begin{itemize}
\item Synchronize operations across stages
\item Store intermediate values
\item Prevent data interference
\item Enable parallel execution

\textbf{Timing Critical:}

\begin{itemize}
\item Write delay + read delay at every stage
\item Pipeline register overhead significant
\item Critical path determines clock period
\item Throughput limited by slowest stage

\subsubsection{Design Principles}

\textbf{Make Common Case Fast:}

\begin{itemize}
\item Memory accesses most critical
\item Optimize memory access time first
\item Cache memory industry solution

\textbf{Balance Pipeline Stages:}

\begin{itemize}
\item Even workload distribution
\item Minimize wasted time
\item Maximize efficiency

\textbf{Control Signals Matter:}

\begin{itemize}
\item Prevent unwanted operations
\item Propagate through pipeline
\item Essential for correctness

\subsubsection{Common Mistakes to Avoid}

\textbf{Write Register Address:}

\begin{itemize}
\item Must propagate through ALL pipeline registers
\item Cannot use current instruction's address
\item 4-cycle delay between fetch and write back

\textbf{Control Signal Errors:}

\begin{itemize}
\item RegWrite must be 0 for store/branch
\item MemRead/MemWrite must be mutually exclusive
\item Incorrect signals cause data corruption

\textbf{Diagram Interpretation:}

\begin{itemize}
\item Verify resource usage carefully
\item Textbooks contain errors
\item Understand shading conventions

\subsubsection{Performance Considerations}

\textbf{Critical Path Analysis:}

\begin{itemize}
\item Identify slowest stage
\item Optimize critical path components
\item Non-critical optimizations don't help throughput

\textbf{Speedup Limitations:}

\begin{itemize}
\item Ideal speedup = number of stages
\item Actual speedup < ideal
\item Reasons:
\item Pipeline register overhead
\item Unbalanced stages
\item Hazards and stalls
\item Pipeline fill/drain time

\subsubsection{Looking Ahead}

\textbf{Memory Hierarchy (Next Topics):}

\begin{itemize}
\item Cache memory introduction
\item Memory performance optimization
\item Cache design and organization
\item Virtual memory
\item Performance bottleneck solutions

\textbf{Real-World Pipelines:}

\begin{itemize}
\item 10-30 stages common
\item Superscalar (multiple issue)
\item Out-of-order execution
\item Speculative execution
\item Branch prediction sophistication

\subsection{Important Formulas}

\subsubsection{Clock Period}

T_clock = max(T_IF, T_ID, T_EX, T_MEM, T_WB)

Where each T_stage includes:
\begin{itemize}
\item Pipeline register write delay
\item Pipeline register read delay
\item Dominant component delay

\subsubsection{Maximum Frequency}

f_max = 1 / T_clock

\subsubsection{Pipeline Speedup}

Speedup = T_non-pipelined / T_pipelined_steady_state
        ≈ Number of stages (ideal)
        < Number of stages (actual)

\subsubsection{Stage Timing General Formula}

T_stage = T_pipe_write + T_pipe_read + T_dominant_component + T_other_parallel

Where parallel components don't add (take maximum)

\subsubsection{Throughput}

Throughput = 1 instruction / T_clock (steady state)

\subsubsection{Latency}

Latency = (Number of stages) $\times$ T_clock + Pipeline overhead

\subsection{Key Takeaways}

\begin{enumerate}
\item \textbf{Four pipeline registers separate five stages}: IF/ID, ID/EX, EX/MEM, MEM/WB store all information needed by subsequent stages.

\begin{enumerate}
\item \textbf{Pipeline registers capture data and control signals}—instruction fields, register values, ALU results, memory data, and control bits all propagate through pipeline.

\begin{enumerate}
\item \textbf{Each register updates on clock edge}—enabling clean separation between pipeline stages and preventing data corruption from simultaneous operations.

\begin{enumerate}
\item \textbf{Load instruction takes 5 cycles to complete}—IF (fetch), ID (decode/read), EX (address calc), MEM (read memory), WB (write register).

\begin{enumerate}
\item \textbf{Store instruction uses 4 active stages}—skips WB stage since no register write occurs, but occupies pipeline for 5 cycles.

\begin{enumerate}
\item \textbf{Instruction and data must travel together}—control signals propagate alongside data through pipeline to ensure correct operations at later stages.

\begin{enumerate}
\item \textbf{Register file has two write ports and three read ports} in practice—enabling simultaneous read in ID and write in WB stages.

\begin{enumerate}
\item \textbf{Forwarding paths bypass pipeline registers}—directly connecting EX/MEM and MEM/WB outputs to ALU inputs for data hazard resolution.

\begin{enumerate}
\item \textbf{Load-use hazard requires pipeline stall}—memory data not available until MEM/WB register, too late for immediate ALU use even with forwarding.

10. \textbf{Clock frequency} = 1 / (Register Delay + Maximum Stage Delay)—pipeline register overhead reduces frequency below ideal calculation.

11. \textbf{Pipeline registers introduce 20-50 ps overhead} per stage—must account for setup/hold times and propagation delays in timing analysis.

12. \textbf{Stage delays must balance for optimal performance}—uneven stages waste time as clock period determined by slowest stage.

13. \textbf{Separate instruction and data caches essential}—prevent structural hazards from simultaneous IF and MEM stage memory access.

14. \textbf{Pipeline depth tradeoff}: Deeper pipelines increase clock frequency but amplify hazard penalties and register overhead.

15. \textbf{Write-back stage coincides with fetch of fifth instruction}—demonstrating true parallelism with five instructions in pipeline simultaneously.

16. \textbf{Control signals generated in ID stage} propagate through pipeline with instruction—EX/MEM/WB stages use stored control bits.

17. \textbf{ALU result available in EX stage} can forward to dependent instruction in EX stage—eliminating most RAW hazard stalls.

18. \textbf{Memory data available in MEM stage} can forward to dependent instruction in EX stage—but not soon enough for load-use case.

19. \textbf{Throughput approaches 1 instruction per cycle} in steady state—achieving near 5$\times$ speedup over single-cycle design.

20. \textbf{Pipeline timing analysis critical for clock frequency determination}—must consider all delay components including registers, logic, and wire delays.

\subsection{Summary}

The detailed examination of MIPS pipeline operation reveals the sophisticated hardware mechanisms that enable efficient instruction-level parallelism through careful staging and register design. Four pipeline registers (IF/ID, ID/EX, EX/MEM, MEM/WB) serve as the critical infrastructure separating five pipeline stages, capturing and propagating not only instruction data but also all control signals needed by downstream stages. The cycle-by-cycle analysis of load and store instructions demonstrates how each pipeline stage performs its designated function while simultaneously handling different instructions—instruction fetch occurring for instruction N while instruction N-1 decodes, N-2 executes, N-3 accesses memory, and N-4 writes back results. This true parallelism, with five instructions simultaneously occupying different pipeline stages, achieves the dramatic throughput improvement that justifies pipeline complexity. The timing analysis introduces crucial practical considerations: pipeline registers add 20-50 picoseconds overhead per stage, stage delays must balance to avoid wasting clock cycles, and clock frequency equals the reciprocal of register delay plus maximum stage delay. Forwarding paths that bypass pipeline registers—connecting EX/MEM and MEM/WB outputs directly to ALU inputs—eliminate most data hazard stalls by making results available before register write-back completes, though load-use hazards still require one-cycle stalls since memory data arrives too late even with forwarding. The register file's dual-port design enables simultaneous reading in ID stage and writing in WB stage, essential for maintaining pipeline flow. Practical exercises in clock frequency calculation reinforce understanding of how component delays, register overhead, and stage balancing determine ultimate processor performance. The separation of instruction and data caches emerges as non-negotiable requirement, preventing structural hazards from simultaneous memory access in IF and MEM stages. This comprehensive pipeline view—from register-level mechanisms through timing analysis to performance optimization—provides essential foundation for understanding real processor implementations and the engineering tradeoffs between pipeline depth, clock frequency, hazard penalties, and design complexity that characterize modern computer architecture.
